---
layout: post
title:  "实习日记20(Redis)"
date:   2021-08-11
categories: jekyll update
---

## Day20

- **Java学习，基于https://github.com/doocs/advanced-java**

- Redis的雪崩、穿透和击穿，其中缓存雪崩和穿透是缓存最大的两个问题

  - 缓存雪崩

    **定义**：假设一个系统A每天高峰期每秒接受5000个请求，本来缓存高峰最多能接收每秒4000个请求，但是缓存机器发生了意外导致全盘宕机，这时每秒5000个请求会流入数据库，同样会导致数据库挂了。此时如果没有解决方案，DBA立即重启数据库，但数据库仍然会因为大量请求挂掉。

    ![redis-caching-avalanche](https://github.com/doocs/advanced-java/raw/main/docs/high-concurrency/images/redis-caching-avalanche.png)

    **解决方案**：

    - 事前：Redis 高可用，主从+哨兵，Redis cluster，避免全盘崩溃。
    - 事中：本地 ehcache 缓存 + hystrix 限流&降级，避免 MySQL 被打死。
    - 事后：Redis 持久化，一旦重启，自动从磁盘上加载数据，快速恢复缓存数据。

    ![redis-caching-avalanche-solution](https://github.com/doocs/advanced-java/raw/main/docs/high-concurrency/images/redis-caching-avalanche-solution.png)

    用户发送一个请求后，系统接收到请求，先检查本地ehcache缓存，如果没查到再查Redis。如果ehcache和Redis都没有的话，会继续查数据库，将数据库中的结果写入ehcache和Redis中。

    限流组件：可以设置每秒的请求通过数，剩余未通过的请求走降级，可以返回一些默认值或者提示或者空值。

    好处：

    - 数据库绝对不会死，限流组件确保了每秒只有多少个请求能通过。
    - 只要数据库不死，就是说，对用户来说，2/5 的请求都是可以被处理的。
    - 只要有 2/5 的请求可以被处理，就意味着系统没死，对用户来说，可能就是点击几次刷不出来页面，但是多点几次，就可以刷出来了。

  - 缓存穿透

    **定义**：假设一个系统A接收5000个请求，但其中有4000个是黑客发出的恶意攻击，在缓存中无法查到，数据库中也无法查到。

    ![redis-caching-penetration](https://github.com/doocs/advanced-java/raw/main/docs/high-concurrency/images/redis-caching-penetration.png)

    **解决方法**：每次系统 A 从数据库中只要没查到，就写一个空值到缓存里去 。然后设置一个过期时间，这样的话，下次有相同的 key 来访问的时候，在缓存失效之前，都可以直接从缓存中取数据。

    如果黑客如果每次使用不同的负数 id 来攻击，写空值的方法可能就不奏效了。更为经常的做法是在缓存之前增加布隆过滤器，将数据库中所有可能的数据哈希映射到布隆过滤器中。然后对每个请求进行如下判断：

    - 请求数据的 key 不存在于布隆过滤器中，可以确定数据就一定不会存在于数据库中，系统可以立即返回不存在。
    - 请求数据的 key 存在于布隆过滤器中，则继续再向缓存中查询。

    使用布隆过滤器能够对访问的请求起到了一定的初筛作用，避免了因数据不存在引起的查询压力。

    ![redis-caching-avoid-penetration](https://github.com/doocs/advanced-java/raw/main/docs/high-concurrency/images/redis-caching-avoid-penetration.png)

  - 缓存击穿

    **定义**：某个key的访问非常频繁，处于集中式高并发的情况，如果这个key失效，会有大量请求涌入击穿缓存，直接请求数据库。
    
    **解决方法**：
    
    - 若缓存的数据是基本不会发生更新的，则可尝试将该热点数据设置为永不过期。
    - 若缓存的数据更新不频繁，且缓存刷新的整个流程耗时较少的情况下，则可以采用基于 Redis、zookeeper 等分布式中间件的分布式互斥锁，或者本地互斥锁以保证仅少量的请求能请求数据库并重新构建缓存，其余线程则在锁释放后能访问到新缓存。
    - 若缓存的数据更新频繁或者在缓存刷新的流程耗时较长的情况下，可以利用定时线程在缓存过期前主动地重新构建缓存或者延后缓存的过期时间，以保证所有的请求能一直访问到对应的缓存。
  
- 缓存与数据库的双写一致性

  如果系统不是严格要求“缓存+数据库”保持一致，尽量不要做读请求和写请求串行化，串到一个内存队列里。因为串行化可以保证一定不会出现不一致的情况，但是它也会导致系统的吞吐量大幅度降低，用比正常情况下多几倍的机器去支撑线上的一个请求。

  - Cache Aside Pattern：最经典的缓存+数据库读写模式

    - 读的时候，先读缓存，缓存没有的话，就读数据库，然后取出数据后放入缓存，同时返回响应。
    - 更新的时候，先更新数据库，然后再删除缓存。

    **为什么是删除缓存而不是更新缓存**

    因为很多时候，在复杂点的缓存场景，缓存不单单是数据库中直接取出来的值，比如可能更新了某个表的一个字段，然后其对应的缓存，是需要查询另外两个表的数据并进行运算，才能计算出缓存最新的值的。

    另外更新缓存的代价有时候是很高的如果你频繁修改一个缓存涉及的多个表，缓存也频繁更新。但是这个缓存不一定会被频繁地访问到。

    其实删除缓存，而不是更新缓存，就是一个懒计算计算的思想，不要每次都重新做复杂的计算，不管它会不会用到，而是让它到需要被使用的时候再重新计算。像 mybatis，hibernate，都有懒加载思想。查询一个部门，部门带了一个员工的 list，没有必要说每次查询部门，都把里面的 1000 个员工的数据也同时查出来啊。80% 的情况，查这个部门，就只是要访问这个部门的信息就可以了。先查部门，同时要访问里面的员工，那么这个时候只有在你要访问里面的员工的时候，才会去数据库里面查询 1000 个员工。
    
  - 最初级的缓存不一致问题
  
    先更新数据库，再删除缓存。如果删除缓存失败了，那么会导致数据库中是新数据，缓存中是旧数据，数据就出现了不一致。
  
    ![redis-junior-inconsistent](https://github.com/doocs/advanced-java/raw/main/docs/high-concurrency/images/redis-junior-inconsistent.png)
  
    **解决思路**：
  
    - 先删除缓存，再更新数据库。如果数据库更新失败了，那么数据库中是旧数据，缓存中是空的，那么数据不会不一致。因为读的时候缓存没有，所以去读了数据库中的旧数据，然后更新到缓存中。
  
    - 延时双删。依旧是先更新数据库，再删除缓存，唯一不同的是，我们把这个删除的动作，在不久之后再执行一次，比如 5s 之后。删除的动作，可以有多种选择，比如：1. 使用 `DelayQueue`，会随着 JVM 进程的死亡，丢失更新的风险；2. 放在 `MQ`，但编码复杂度为增加
  
      ```java
      public void set(key, value) {
          putToDb(key, value);
          deleteFromRedis(key);
      
          // ... a few seconds later
          deleteFromRedis(key);
      }
      ```
  
  - 比较复杂的数据不一致问题
  
    数据发生了变更，先删除了缓存，然后要去修改数据库，此时还没修改。一个请求过来，去读缓存，发现缓存空了，去查询数据库，查到了修改前的旧数据，放到了缓存中。随后数据变更的程序完成了数据库的修改，导致缓存与数据库数据不一致。
  
    这种问题容易出现在上亿流量高并发场景下。只有在对一个数据在并发的进行读写的时候，才可能会出现这种问题。其实如果说并发量很低的话，特别是读并发很低，每天访问量就 1 万次，那么很少的情况下，会出现刚才描述的那种不一致的场景。但是问题是，如果每天的是上亿的流量，每秒并发读是几万，每秒只要有数据更新的请求，就可能会出现上述的数据库+缓存不一致的情况。
  
    **解决方案**：
  
    更新数据的时候，根据数据的**唯一标识**，将操作路由之后，发送到一个 jvm 内部队列中。读取数据的时候，如果发现数据不在缓存中，那么将重新执行“读取数据+更新缓存”的操作，根据唯一标识路由之后，也发送到同一个 jvm 内部队列中。
  
    一个队列对应一个工作线程，每个工作线程**串行**拿到对应的操作，然后一条一条的执行。这样的话，一个数据变更的操作，先删除缓存，然后再去更新数据库，但是还没完成更新。此时如果一个读请求过来，没有读到缓存，那么可以先将缓存更新的请求发送到队列中，此时会在队列中积压，然后同步等待缓存更新完成。
  
    这里有一个**优化点**，一个队列中，其实多个更新缓存请求串在一起是没意义的，因此可以做过滤，如果发现队列中已经有一个更新缓存的请求了，那么就不用再放个更新请求操作进去了，直接等待前面的更新操作请求完成即可。
  
    待那个队列对应的工作线程完成了上一个操作的数据库的修改之后，才会去执行下一个操作，也就是缓存更新的操作，此时会从数据库中读取最新的值，然后写入缓存中。
  
    如果请求还在等待时间范围内，不断轮询发现可以取到值了，那么就直接返回；如果请求等待的时间超过一定时长，那么这一次直接从数据库中读取当前的旧值。
  
    高并发的场景下，该解决方案要注意的问题：
  
    - 读请求长时阻塞
  
      由于读请求进行了非常轻度的异步化，所以一定要注意读超时的问题，每个读请求必须在超时时间范围内返回。
  
      该解决方案，最大的风险点在于说，可能数据更新很频繁，导致队列中积压了大量更新操作在里面，然后读请求会发生大量的超时，最后导致大量的请求直接走数据库。务必通过一些模拟真实的测试，看看更新数据的频率是怎样的。
  
      另外一点，因为一个队列中，可能会积压针对多个数据项的更新操作，因此需要根据自己的业务情况进行测试，可能需要部署多个服务，每个服务分摊一些数据的更新操作。比如，如果一个内存队列里居然会挤压 100 个商品的库存修改操作，每个库存修改操作要耗费 10ms 去完成，那么最后一个商品的读请求，可能等待 10 * 100 = 1000ms = 1s 后，才能得到数据，这个时候就导致读请求的长时阻塞。
  
      如果一个内存队列中可能积压的更新操作特别多，那么就要加机器，让每个机器上部署的服务实例处理更少的数据，那么每个内存队列中积压的更新操作就会越少。
  
    - 读请求并发量过高
  
      这里还必须做好压力测试，确保恰巧碰上上述情况的时候，还有一个风险，就是突然间大量读请求会在几十毫秒的延时 hang 在服务上，看服务能不能扛的住，需要多少机器才能扛住最大的极限情况的峰值。
  
      但是因为并不是所有的数据都在同一时间更新，缓存也不会同一时间失效，所以每次可能也就是少数数据的缓存失效了，然后那些数据对应的读请求过来，并发量应该也不会特别大。
  
    - 多服务实例部署的请求路由
  
      可能这个服务部署了多个实例，那么必须保证，执行数据更新操作，以及执行缓存更新操作的请求，都通过 Nginx 服务器
  
    - 热点商品的路由问题，导致请求的倾斜
  
      万一某个商品的读写请求特别高，全部打到相同的机器的相同的队列里面去了，可能会造成某台机器的压力过大。就是说，因为只有在商品数据更新的时候才会清空缓存，然后才会导致读写并发，所以其实要根据业务系统去看，如果更新频率不是太高的话，这个问题的影响并不是特别大，但是的确可能某些机器的负载会高一些。
  
- Redis并发竞争问题

  **定义**：多客户端同时并发写一个key，可能本来应该先到的数据后到了，导致数据版本错了；或者是多客户端同时获取一个 key，修改值之后再写回去，只要顺序错了，数据就错了。Redis自己有能解决这个问题的CAS类的乐观锁方案。

  某个时刻，多个系统实例都去更新某个 key。可以基于 zookeeper 实现分布式锁。每个系统通过 zookeeper 获取分布式锁，确保同一时间，只能有一个系统实例在操作某个 key，别人都不允许读和写。

  ![zookeeper-distributed-lock](https://github.com/doocs/advanced-java/raw/main/docs/high-concurrency/images/zookeeper-distributed-lock.png)

  要写入缓存的数据，都是从 mysql 里查出来的，都得写入 mysql 中，写入 mysql 中的时候必须保存一个时间戳，从 mysql 查出来的时候，时间戳也查出来。

  每次要写之前，先判断一下当前这个 value 的时间戳是否比缓存里的 value 的时间戳要新。如果是的话，那么可以写，否则，就不能用旧的数据覆盖新的数据。