---
layout: post
title:  "实习日记22(工作+面经+MYSQL主从分离+dubbo)"
date:   2021-08-13
categories: jekyll update
---

## Day22

- 工作开发，新增查询，单纯地修改某个controller，没什么好说的，等下和负责人确认下需求并学习一下测试流程之类的。

- 昨晚的面试有一个数据库索引优先级没有答出来，现在把查的结果放在下面：

  - 最左前缀：即最左优先

    ![img](https://img2020.cnblogs.com/blog/1541798/202005/1541798-20200527220708288-482441355.png)

    原理：b+ 树的数据项是复合的数据结构，比如 (name,age,sex) 的时候，b+ 树是按照从左到右的顺序来建立搜索树的，比如当 (张三,20,F) 这样的数据来检索的时候，b+ 树会优先比较 name 来确定下一步的所搜方向，如果 name 相同再依次比较 age 和 sex，最后得到检索的数据；但当 (20,F) 这样的没有 name 的数据来的时候，b+ 树就不知道第一步该查哪个节点，因为建立搜索树的时候 name 就是第一个比较因子，必须要先根据 name 来搜索才能知道下一步去哪里查询

    比如当 (张三, F) 这样的数据来检索时，b+ 树可以用 name 来指定搜索方向，但下一个字段 age 的缺失，所以只能把名字等于张三的数据都找到，然后再匹配性别是 F 的数据了， 这个是非常重要的性质，即索引的最左匹配特性。（这种情况无法用到联合索引）

- Java学习，基于https://github.com/doocs/advanced-java

  - MYSQL读写分离和主从复制

    一般情况下许多app或网站都是读多写少，索引针对这样以一个情况，基本是写一个主库，主库挂多个从库，然后从多个从库来读，从而能支撑更高的读并发压力。

    - MYSQL主从复制原理

      主库将变更写入 binlog 日志，然后从库连接到主库之后，从库有一个 IO 线程，将主库的 binlog 日志拷贝到自己本地，写入一个 relay 中继日志中。接着从库中有一个 SQL 线程会从中继日志读取 binlog，然后执行 binlog 日志中的内容，也就是在自己本地再次执行一遍 SQL，这样就可以保证自己跟主库的数据是一样的。

      从库同步主库数据的过程是串行化的，也就是说主库上并行的操作，在从库上会串行执行。所以这就是一个非常重要的点了，由于从库从主库拷贝日志以及串行执行 SQL 的特点，在高并发场景下，从库的数据一定会比主库慢一些，是**有延时**的。所以经常出现，刚写入主库的数据可能是读不到的，要过几十毫秒，甚至几百毫秒才能读取到。

      如果主库突然宕机，然后恰好数据还没同步到从库，那么有些数据可能在从库上是没有的，有些数据可能就丢失了。所以 MySQL 实际上在这一块有两个机制，一个是**半同步复制**，用来解决主库数据丢失问题；一个是**并行复制**，用来解决主从同步延时问题。

      **半同步复制**，也叫 `semi-sync` 复制，指的就是主库写入 binlog 日志之后，就会将**强制**此时立即将数据同步到从库，从库将日志写入自己本地的 relay log 之后，接着会返回一个 ack 给主库，主库接收到**至少一个从库**的 ack 之后才会认为写操作完成了。

      **并行复制**，指的是从库开启多个线程，并行读取 relay log 中不同库的日志，然后**并行重放不同库的日志**，这是库级别的并行。

    - MYSQL主从同步延时问题

      先插入一条数据，再把它查出来，然后更新这条数据。在生产环境高峰期，写并发达到了 2000/s，这个时候，主从复制延时大概是在小几十毫秒。线上会发现，每天总有那么一些数据，我们期望更新一些重要的数据状态，但在高峰期时候却没更新。

      主从同步较为严重时**解决方案**：

      - 分库，将一个主库拆分为多个主库，每个主库的写并发就减少了几倍，此时主从延迟可以忽略不计。
      - 打开 MySQL 支持的并行复制，多个库并行复制。如果说某个库的写入并发就是特别高，单库写并发达到了 2000/s，并行复制还是没意义。
      - 重写代码，插入数据时立马查询可能查不到。
      - 如果确实是存在必须先插入，立马要求就查询到，然后立马就要反过来执行一些操作，对这个查询**设置直连主库**。不推荐这种方法，因为这样做读写分离的意义就丧失了。

- 高并发架构设计

  可以分为以下6点来说：

  - 系统拆分：将一个系统拆分为多个子系统，用 dubbo 来搞。然后每个系统连一个数据库
  - 缓存：部分的高并发场景，都是**读多写少**，完全可以在数据库和缓存里都写一份，然后读的时候大量走缓存，那些承载主要请求的读场景，用缓存来抗高并发。
  - MQ：大量的写请求灌入 MQ 里，排队慢慢玩儿，**后边系统消费后慢慢写**，控制在 mysql 承载范围之内
  - 分库分表：将一个数据库拆分为多个库，多个库来扛更高的并发；然后将一个表**拆分为多个表**，每个表的数据量保持少一点，提高 sql 跑的性能。
  - 读写分离：大部分时候数据库可能也是读多写少，没必要所有请求都集中在一个库上吧，可以搞个主从架构，**主库写**入，**从库读**取，搞一个读写分离。**读流量太多**的时候，还可以**加更多的从库**。
  - ElasticSearch：es 是分布式的，可以随便扩容，分布式天然就可以支撑高并发，因为动不动就可以扩容加机器来扛更高的并发。那么一些比较简单的查询、统计类的操作，可以考虑用 es 来承载，还有一些全文搜索类的操作，也可以考虑用 es 来承载。

- 系统拆分

  **为什么要进行系统拆分**：如果不拆分系统，开发效率极其低下，问题很多。但是拆分系统之后，每个人就负责自己的一小部分就好了，可以随便玩儿随便弄。分布式系统拆分之后，可以大幅度提升复杂系统大型团队的开发效率。

  - 如何进行系统拆分

    系统拆分为分布式系统，拆成多个服务，拆成微服务的架构，是需要拆很多轮的。并不是说上来一个架构师一次就给拆好了，而以后都不用拆。

    大部分的系统，是要进行**多轮拆分**的，第一次拆分，可能就是将以前的多个模块该拆分开来了，但是后面可能每个系统又变得越来越复杂了。核心意思就是根据情况，先拆分一轮，后面如果系统更复杂了，可以继续分拆。

  - 拆分后能否不适用dubbo

    当然可以了，大不了最次，就是各个系统之间，直接基于 spring mvc，就纯 http 接口互相通信呗，还能咋样。但是这个肯定是有问题的，因为 http 接口通信维护起来成本很高，你要考虑**超时重试**、**负载均衡**等等各种乱七八糟的问题，比如说你的订单系统调用商品系统，商品系统部署了 5 台机器，你怎么把请求均匀地甩给那 5 台机器？这不就是负载均衡？你要是都自己搞那是可以的，但是确实很痛苦。

    所以 dubbo 说白了，是一种 rpc 框架，就是说本地就是进行接口调用，但是 dubbo 会代理这个调用请求，跟远程机器网络通信，给你处理掉负载均衡、服务实例上下线自动感知、超时重试等等乱七八糟的问题。那你就不用自己做了，用 dubbo 就可以了。

- dubbo原理

  - dubbo分层：
    - 第一层：service 层，接口层，给服务提供者和消费者来实现的
    - 第二层：config 层，配置层，主要是对 dubbo 进行各种配置的
    - 第三层：proxy 层，服务代理层，无论是 consumer 还是 provider，dubbo 都会给你生成代理，代理之间进行网络通信
    - 第四层：registry 层，服务注册层，负责服务的注册与发现
    - 第五层：cluster 层，集群层，封装多个服务提供者的路由以及负载均衡，将多个实例组合成一个服务
    - 第六层：monitor 层，监控层，对 rpc 接口的调用次数和调用时间进行监控
    - 第七层：protocal 层，远程调用层，封装 rpc 调用
    - 第八层：exchange 层，信息交换层，封装请求响应模式，同步转异步
    - 第九层：transport 层，网络传输层，抽象 mina 和 netty 为统一接口
    - 第十层：serialize 层，数据序列化层
  - 工作流程：
    - 第一步：provider 向注册中心去注册
    - 第二步：consumer 从注册中心订阅服务，注册中心会通知 consumer 注册好的服务
    - 第三步：consumer 调用 provider
    - 第四步：consumer 和 provider 都异步通知监控中心

  如果注册中心挂了，但因为刚开始初始化的时候，消费者会将提供者的地址等信息拉取到本地缓存，所以仍然能继续通信。

- dubbo序列化协议

  **序列化**：把数据结构或者是一些对象，转换为二进制串的过程

  **反序列化**：将在序列化过程中所生成的二进制串转换成数据结构或者对象的过程

  - dubbo支持的不同通信协议

    - dubbo 协议 `dubbo://`

      默认走dubbo协议，单一长连接，进行的是 NIO 异步通信，基于 hessian 作为序列化协议。

      **使用场景**：传输数据量小（每次请求在 100kb 以内），但是并发量很高，以及服务消费者机器数远大于服务提供者机器数的情况。为了要支持高并发场景，一般是服务提供者就几台机器，但是服务消费者有上百台，可能每天调用量达到上亿次！此时用长连接是最合适的，就是跟每个服务消费者维持一个长连接就可以，可能总共就 100 个连接。然后后面直接基于长连接 NIO 异步通信，可以支撑高并发请求。

      **PS**：长连接：建立连接过后可以持续发送请求，无须再建立连接。

      ![在这里插入图片描述](https://img-blog.csdnimg.cn/20200903082529499.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1NvcGhpYV8wMzMx,size_16,color_FFFFFF,t_70#pic_center)

      ​		 短链接：每次要发送请求之前，需要先重新建立一次连接。

      ![在这里插入图片描述](https://img-blog.csdnimg.cn/2020090308263510.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1NvcGhpYV8wMzMx,size_16,color_FFFFFF,t_70#pic_center)

    - rmi 协议 `rmi://`

      RMI 协议采用 JDK 标准的 java.rmi.* 实现，采用阻塞式短连接和 JDK 标准序列化方式。多个短连接。

      **使用场景**：适合消费者和提供者数量差不多的情况，适用于文件的传输，一般较少用。

    - http 协议 `http://`

      基于 HTTP 表单的远程调用协议，采用 Spring 的 HttpInvoker 实现。走表单序列化。

    - thrift 协议 `thrift://`

      当前 dubbo 支持的 thrift 协议是对 thrift 原生协议的扩展，在原生协议的基础上添加了一些额外的头信息，比如 service name，magic number 等。

    - webservice `webservice://`

      基于 WebService 的远程调用协议，基于 Apache CXF 的 frontend-simple 和 transports-http 实现。走 SOAP 文本序列化。

    - memcached 协议 `memcached://`

      基于 memcached 实现的 RPC 协议。

    - redis 协议 `redis://`

      基于 Redis 实现的 RPC 协议。

    - rest 协议 `rest://`

      基于标准的 Java REST API——JAX-RS 2.0（Java API for RESTful Web Services 的简写）实现的 REST 调用支持。

    - gPRC 协议 `grpc://`

      Dubbo 自 2.7.5 版本开始支持 gRPC 协议，对于计划使用 HTTP/2 通信，或者想利用 gRPC 带来的 Stream、反压、Reactive 编程等能力的开发者来说， 都可以考虑启用 gRPC 协议。

  - dubbo支持序列化的协议：dubbo 支持 hession、Java 二进制序列化、json、SOAP 文本序列化多种序列化协议。但是 hessian 是其默认的序列化协议。

  - Hessian数据结构

    **原始数据类型**：

    - 原始二进制数据
    - boolean
    - 64-bit date（64 位毫秒值的日期）
    - 64-bit double
    - 32-bit int
    - 64-bit long
    - null
    - UTF-8 编码的 string

    **递归类型**：

    - list for lists and arrays
    - map for maps and dictionaries
    - object for objects

    **特殊类型**：

    - ref：用来表示对共享对象的引用。

  - 为什么PB的效率最高：其实 PB 之所以性能如此好，主要得益于两个：**第一**，它使用 proto 编译器，自动进行序列化和反序列化，速度非常快，应该比 `XML` 和 `JSON` 快上了20~100倍；**第二**，它的数据压缩效果好，就是说它序列化后的数据量体积小。因为体积小，传输起来带宽和速度上会有优化。

