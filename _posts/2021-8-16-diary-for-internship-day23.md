---
layout: post
title:  "实习日记23(dubbo)"
date:   2021-08-16
categories: jekyll update
---

## Day23

- **Java学习，基于https://github.com/doocs/advanced-java**

- dubbo负载均衡策略

  - RandomLoadBalance

    默认情况下dubbo使用RandomLoadBalance，即随机调用实现负载均衡，可以对provider不同实例设置不同的权重，会按照权重来负载均衡，权重越大分配流量越高，一般都使用这个策略。

    **算法思想**：假设有一组服务器 servers = `[A, B, C]`，他们对应的权重为 weights = `[5, 3, 2]`，权重总和为 10。现在把这些权重值平铺在一维坐标值上，`[0, 5)` 区间属于服务器 A，`[5, 8)` 区间属于服务器 B，`[8, 10)` 区间属于服务器 C。接下来通过随机数生成器生成一个范围在 `[0, 10)` 之间的随机数，然后计算这个随机数会落到哪个区间上。权重越大的机器，在坐标轴上对应的区间范围就越大，因此随机数生成器生成的数字就会有更大的概率落到此区间内。只要随机数生成器产生的随机数分布性很好，在经过多次选择后，每个服务器被选中的次数比例接近其权重比例

  - RoundRobinLoadBalance

    默认均匀地将流量打到各个机器上去，但是如果各个机器的性能不一样，容易导致性能差的机器负载过高。所以此时需要调整权重，让性能差的机器承载权重小一些，流量少一些。

  - LeastActiveLoadBalance

    官网解释为"最小活跃数负载均衡"，活跃调用数越小，表明该服务提供者效率越高，单位时间内可处理更多的请求，那么此时请求会优先分配给服务提供者。

    **算法思想**：每个服务提供者对应一个活跃数`active`。初始情况下，所有服务提供者的活跃数`active`均为0，每当收到一个请求，对应的服务提供者的`active`会增加1，处理完请求后，`active`会减1。所以如果服务器的性能较好，处理请求的效率高，那么其`active`也会下降得快。因此可以给这样的服务提供者优先分配请求。

    除了最小活跃数，该算法在实现上还引入了权重值。所以准确地来说，该算法是基于加权最小活跃数算法实现的。

  - ConsistentHashLoadBalance

    一致性哈希算法，相同参数的请求一定分发到一个provider上，provider挂掉的时候，会基于虚拟节点均匀分配剩余的流量，抖动不会太大。如果用户不是需要随机负载均衡，是要一类都请求到一个节点，那就走这个一致性hash策略。

  - 关于 dubbo 负载均衡策略更加详细的描述，可以查看官网 http://dubbo.apache.org/zh-cn/docs/source_code_guide/loadbalance.html 。

- dubbo集群容错策略

  - Failover Cluster模式

    默认侧录，失败自动切换，自动重试其他机器，常见于读操作（失败重试其他机器）

    可以通过以下方式配置重试次数：

    ```html
    <dubbo:service retries="2" />
    ```

    或者

    ```html
    <dubbo:reference retries="2" />
    ```

    或者

    ```html
    <dubbo:reference>
        <dubbo:method name="findFoo" retries="2" />
    </dubbo:reference>
    ```

  - Failfast Cluster模式

    一次调用失败就立即失败，常见于非幂等性的写操作，比如新增一条记录（调用失败就立即失败）

  - Failsafe Cluster模式

    出现异常时忽略掉，冲用于不重要的接口调用，比如记录日志。

    配置示例如下：

    ```html
    <dubbo:service cluster="failsafe" />
    ```

    或：

    ```html
    <dubbo:reference cluster="failsafe" />
    ```

  - Failback Cluster模式

    失败了后台自动记录请求，然后定时重发，比较适合于写消息队列这种。

  - Forking Cluster模式

    并行调用多个 provider，只要一个成功就立即返回。常用于实时性要求比较高的读操作，但是会浪费更多的服务资源，可通过 `forks="2"` 来设置最大并行数。

  - Broadcast Cluster模式

    逐个调用所有的 provider。任何一个 provider 出错则报错（从 `2.1.0` 版本开始支持）。通常用于通知所有提供者更新缓存或日志等本地资源信息。

  - 关于 dubbo 集群容错策略更加详细的描述，可以查看官网 http://dubbo.apache.org/zh-cn/docs/source_code_guide/cluster.html 。

- dubbo动态代理策略：默认使用 javassist 动态字节码生成，创建代理类。但是可以通过 spi 扩展机制配置自己的动态代理策略。

- dubbo的spi思想

  - spi思想，即`service provider interface`，根据指定的配置或者默认的配置，找到某个接口对应的实现类进行加载，然后用这个实现类的实例对象。

    spi机制一般使用在插件扩展的场景。

  - Java spi思想的体现

    Java定义了一套JDBC的接口，但是并没有提供JDBC的实现类。但是在项目实际跑起来的情况下，开发者会根据自己使用的数据库引入具体的实现类。在系统运行的时候，遇到使用的JDBC接口类，会在底层使用引入的jar类中提供的实现类。

  - dubbo的spi思想

    dubbo使用的是自己提供的spi机制。

    ```java
    Protocol protocol = ExtensionLoader.getExtensionLoader(Protocol.class).getAdaptiveExtension();
    ```

    Protocol 接口，在系统运行的时候，dubbo 会判断一下应该选用这个 Protocol 接口的哪个实现类来实例化对象来使用。

    它会去找一个用户配置的 Protocol，将配置的 Protocol 实现类，加载到 jvm 中来，然后实例化对象，就用那个 Protocol 实现类就可以了。

    上面那行代码就是 dubbo 里大量使用的，就是对很多组件，都是保留一个接口和多个实现，然后在系统运行的时候动态根据配置去找到对应的实现类。如果没配置，那就走默认的实现。

    ```java
    @SPI("dubbo")
    public interface Protocol {
    
        int getDefaultPort();
    
        @Adaptive
        <T> Exporter<T> export(Invoker<T> invoker) throws RpcException;
    
        @Adaptive
        <T> Invoker<T> refer(Class<T> type, URL url) throws RpcException;
    
        void destroy();
    
    }
    ```

    `@SPI("dubbo")` 说的是，通过 SPI 机制来提供实现类，实现类是通过 dubbo 作为默认 key 去配置文件里找到的，配置文件名称与接口全限定名一样的，通过 dubbo 作为 key 可以找到默认的实现类就是 `com.alibaba.dubbo.rpc.protocol.dubbo.DubboProtocol` 。

    如果想要动态替换掉默认的实现类，需要使用 `@Adaptive` 接口，Protocol 接口中，有两个方法加了 `@Adaptive` 注解，就是说那俩接口会被代理实现。

  - 如何自己扩展dubbo组件

    自己写个工程，要是那种可以打成 jar 包的，里面的 `src/main/resources` 目录下，搞一个 `META-INF/services` ，里面放个文件叫： `com.alibaba.dubbo.rpc.Protocol` ，文件里搞一个 `my=com.bingo.MyProtocol` 。自己把 jar 弄到 nexus 私服里去。

    然后自己搞一个 `dubbo provider` 工程，在这个工程里面依赖你自己搞的那个 jar，然后在 spring 配置文件里给个配置：

    ```xml
    <dubbo:protocol name=”my” port=”20000” />
    ```

    provider 启动的时候，就会加载到我们 jar 包里的 `my=com.bingo.MyProtocol` 这行配置里，接着会根据你的配置使用你定义好的 MyProtocol 了，这个就是简单说明一下，你通过上述方式，可以替换掉大量的 dubbo 内部的组件，就是扔个你自己的 jar 包，然后配置一下即可。

    dubbo 里面提供了大量的类似上面的扩展点，就是说，你如果要扩展一个东西，只要自己写个 jar，让你的 consumer 或者是 provider 工程，依赖你的那个 jar，在你的 jar 里指定目录下配置好接口名称对应的文件，里面通过 `key=实现类` 。

    然后对于对应的组件，类似 `<dubbo:protocol>` 用你的那个 key 对应的实现类来实现某个接口，你可以自己去扩展 dubbo 的各种功能，提供你自己的实现。

- dubbo服务治理、服务降级、失败重试和超时重试

  - 服务治理：企业为了确保事情顺利完成而实施的过程，包括最佳实践、架构原则、治理规程、规律以及其他决定性的因素。服务治理指的是用来管理SOA的采用和实现的过程。(不确定，来自Anne Thomas Manes)

    - 调用链路自动生成

      分布式系统由大量的服务组成，在基于 dubbo 做的分布式系统中，对各个服务之间的调用自动记录下来，然后自动将**各个服务之间的依赖关系和调用链路生成出来**，做成一张图，用于显示服务之间互相如何调用。

    - 服务访问压力以及时长统计

      自动统计各个接口和服务之间的调用次数以及访问延时，而且分成两个级别：

      - 接口粒度，就是每个服务的每个接口每天被调用多少次，TP50/TP90/TP99，三个档次的请求延时分别是多少；
      - 从源头入口开始，一个完整的请求链路经过几十个服务之后，完成一次请求，每天全链路走多少次，全链路请求延时的 TP50/TP90/TP99，分别是多少。

      之后可以通过这个看当前系统的压力主要在哪里，如何来扩容和优化

    - 服务分层(避免循环依赖)

    - 调用链路失败监控和报警

    - 服务鉴权

    - 每个服务的可用性的监控(接口调用成功率)

  - 服务降级：比如说服务 A 调用服务 B，结果服务 B 挂掉了，服务 A 重试几次调用服务 B，还是不行，那么直接降级，走一个备用的逻辑，给用户返回响应。

  - 失败重试&超时重试： consumer 调用 provider 要是失败了，比如抛异常了，此时应该是可以重试的，或者调用超时了也可以重试。

    配置如下：

    ```xml
    <dubbo:reference id="xxxx" interface="xx" check="true" async="false" retries="3" timeout="2000"/>
    ```

    其中：

    - `timeout` ：一般设置为 `200ms` ，我们认为不能超过 `200ms` 还没返回。
    - `retries` ：设置 retries，一般是在读请求的时候，比如你要查询个数据，你可以设置个 retries，如果第一次没读到，报错，重试指定的次数，尝试再次读取。

    具体值需联系实际业务设置

- 分布式接口服务的幂等性

  - 幂等性定义：就是说一个接口，多次发起同一个请求，你这个接口得保证结果是准确的，
  - 保证幂等性主要是以下三点：
    - 对于每个请求必须有一个唯一的标识，举个栗子：订单支付请求，肯定得包含订单 id，一个订单 id 最多支付一次，对吧。
    - 每次处理完请求之后，必须有一个记录标识这个请求处理过了。常见的方案是在 mysql 中记录个状态啥的，比如支付之前记录一条这个订单的支付流水。
    - 每次接收请求需要进行判断，判断之前是否处理过。比如说，如果有一个订单已经支付了，就已经有了一条支付流水，那么如果重复发送这个请求，则此时先插入支付流水，orderId 已经存在了，唯一键约束生效，报错插入不进去的。然后你就不用再扣款了。

- 分布式接口请求的顺序性如何保证

  一般来说是不用保证顺序的。但是有时候可能确实是需要严格的顺序保证。例如，服务A调用服务B，先插入再删除，如果插入请求因为某些原因慢了一步，导致删除请求先执行，会导致删除数据无效。

  从业务逻辑上设计的这个系统最好是不需要这种顺序性的保证，因为一旦引入顺序性保障，比如使用分布式锁，会导致系统复杂度上升，而且会带来效率低下，热点数据压力过大等问题。

  如果一定需要保证，用 Dubbo 的一致性 hash 负载均衡策略，将比如某一个订单 id 对应的请求都给分发到某个机器上去，接着就是在那个机器上，因为可能还是多线程并发执行的，你可能得立即将某个订单 id 对应的请求扔一个**内存队列**里去，强制排队，这样来确保他们的顺序性。但是这样引发的后续问题就很多，比如说要是某个订单对应的请求特别多，造成某台机器成**热点**怎么办？解决这些问题又要开启后续一连串的复杂技术方案等。

  最好是比如说刚才那种，一个订单的插入和删除操作，能不能合并成一个操作，就是一个删除，或者是其它什么，避免这种问题的产生。

- CAP定理

  - 什么是CAP定理

    在理论计算机科学中，CAP 定理（CAP theorem），又被称作布鲁尔定理（Brewer's theorem），它指出对于一个分布式计算系统来说，不可能同时满足以下三点：

    - 一致性（Consistency） （等同于所有节点访问同一份最新的数据副本）
    - 可用性（Availability）（每次请求都能获取到非错的响应——但是不保证获取的数据为最新数据）
    - 分区容错性（Partition tolerance）（以实际效果而言，分区相当于对通信的时限要求。系统如果不能在时限内达成数据一致性，就意味着发生了分区的情况，必须就当前操作在 C 和 A 之间做出选择。）

  - 分区容错性

    理解 CAP 理论的最简单方式是想象两个节点分处分区两侧。允许至少一个节点更新状态会导致数据不一致，即丧失了 C 性质。如果为了保证数据一致性，将分区一侧的节点设置为不可用，那么又丧失了 A 性质。除非两个节点可以互相通信，才能既保证 C 又保证 A，这又会导致丧失 P 性质。

    - P 指的是分区容错性，分区现象产生后需要容错，容错是指在 A 与 C 之间选择。如果分布式系统没有分区现象（没有出现不一致不可用情况） 本身就没有分区 ，既然没有分区则就更没有分区容错性 P。
    - 无论我设计的系统是 AP 还是 CP 系统如果没有出现不一致不可用。 则该系统就处于 CA 状态
    - P 的体现前提是得有分区情况存在

  - 几个常用的CAP框架：

    - Eureka

      > Eureka 保证了可用性，实现最终一致性。

      Eureka 所有节点都是平等的所有数据都是相同的，且 Eureka 可以相互交叉注册。
      Eureka client 使用内置轮询负载均衡器去注册，有一个检测间隔时间，如果在一定时间内没有收到心跳，才会移除该节点注册信息；如果客户端发现当前 Eureka 不可用，会切换到其他的节点，如果所有的 Eureka 都跪了，Eureka client 会使用最后一次数据作为本地缓存；所以以上的每种设计都是他不具备`一致性`的特性。

      注意：因为 EurekaAP 的特性和请求间隔同步机制，在服务更新时候一般会手动通过 Eureka 的 api 把当前服务状态设置为`offline`，并等待 2 个同步间隔后重新启动，这样就能保证服务更新节点对整体系统的影响

    - Zookeeper

      > 强一致性

      Zookeeper 在选举 leader 时会停止服务，只有成功选举 leader 成功后才能提供服务，选举时间较长；内部使用 paxos 选举投票机制，只有获取半数以上的投票才能成为 leader，否则重新投票，所以部署的时候最好集群节点不小于 3 的奇数个（但是谁能保证跪掉后节点也是基数个呢）；Zookeeper 健康检查一般是使用 tcp 长链接，在内部网络抖动时或者对应节点阻塞时候都会变成不可用，这里还是比较危险的；

    - Consul

      和 Zookeeper 一样数据 CP

      Consul 注册时候只有过半的节点都写入成功才认为注册成功；leader 挂掉时，重新选举期间整个 Consul 不可用,保证了强一致性但牺牲了可用性
      有很多 blog 说 Consul 属于 ap，官方已经确认他为 CP 机制 原文地址：https://www.consul.io/docs/intro/vs/serf

